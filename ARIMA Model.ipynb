{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code in this notebook is used to plot PACF and ACF plots of the correlation coefficient matrix calculated earlier.\n",
    "Also methods which fit and evaluate ARIMA models are also present here. Afte rprediction, residual values are \n",
    "saved in csv's which will be later fed to LSTM model for drawing non linear tendencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 1 -Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "from pmdarima.arima import ARIMA, auto_arima\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 2 - Load correlation coefficient matrix\n",
    "\n",
    "data_df = pd.read_csv('/Users/gauravthapliyal/Desktop/Project Data/stock_correlation_prediction/Correlation_Matrix.csv')\n",
    "data_df = data_df.loc[:, ~data_df.columns.str.contains('^Unnamed')]\n",
    "print(data_df.shape)\n",
    "\n",
    "num_list = []\n",
    "for i in range(24):\n",
    "    num_list.append(str(i))\n",
    "data_df = data_df[num_list].copy()\n",
    "data_df = np.transpose(data_df)\n",
    "print(data_df.shape)\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Break down data in 4 equal parts which will be treated as train/dev/test1/test2 values.\n",
    "#These values will act as the actual values and predicted values will be matched against these.\n",
    "\n",
    "indices = [20*k for k in range(55875)]\n",
    "data_df = pd.DataFrame(data_df[indices])\n",
    "\n",
    "train = []\n",
    "dev = []\n",
    "test1 = []\n",
    "test2 = []\n",
    "\n",
    "#division of data in 4 parts\n",
    "for i in range(data_df.shape[1]):\n",
    "    tmp = data_df[20*i].copy()\n",
    "    train.append(tmp[:21])\n",
    "    dev.append(tmp[1:22])\n",
    "    test1.append(tmp[2:23])\n",
    "    test2.append(tmp[3:24])\n",
    "    \n",
    "train = pd.DataFrame(train)\n",
    "dev = pd.DataFrame(dev)\n",
    "test1 = pd.DataFrame(test1)\n",
    "test2 = pd.DataFrame(test2)\n",
    "\n",
    "# saving data sets to csv\n",
    "train.to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaTrain.csv')\n",
    "dev.to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaDev.csv')\n",
    "test1.to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaTest1.csv')\n",
    "test2.to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaTest2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cell 4 - Plot ACF and PACF plots for the train dat set\n",
    "\n",
    "train = pd.read_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaTrain.csv')\n",
    "train = np.transpose(train.loc[:, ~train.columns.str.contains('^Unnamed')])\n",
    "#Plotting random data from train dataset to get a idea of the distribution. This helps in determining parameters\n",
    "#for SARIMAX model\n",
    "for _ in range(100):\n",
    "    randint = random.randrange(0,55875,1)\n",
    "    print(randint)\n",
    "    train[randint].plot()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plot_acf(train[randint].diff()[1:])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plot_pacf(train[randint].diff()[1:])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print('-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = pd.DataFrame()\n",
    "for i in range(55875):\n",
    "    df = train[i].describe()\n",
    "    stat[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 5 - ARIMA Model\n",
    "\n",
    "#Load data from train, dev, test set\n",
    "\n",
    "train = pd.read_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaTrain.csv')\n",
    "dev = pd.read_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaDev.csv')\n",
    "test1 = pd.read_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaTest1.csv')\n",
    "test2 = pd.read_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Pre_ARIMA/ArimaTest2.csv')\n",
    "\n",
    "\n",
    "train = np.transpose(train.loc[:,~train.columns.str.contains('^Unnamed')])\n",
    "dev = np.transpose(dev.loc[:,~dev.columns.str.contains('^Unnamed')])\n",
    "test1 = np.transpose(test1.loc[:,~test1.columns.str.contains('^Unnamed')])\n",
    "test2 = np.transpose(test2.loc[:,~test2.columns.str.contains('^Unnamed')])\n",
    "\n",
    "datasets = [train, dev, test1, test2]\n",
    "\n",
    "\n",
    "#Models which we will be using to fit ARIMA model.\n",
    "#We have taken a seasonal order of 12 \n",
    "#p, d, q have standard ARIMA model values\n",
    "\n",
    "model_110 = ARIMA(order=(1,1,0), mle_regression=True, suppress_warnings=True)\n",
    "model_011 = ARIMA(order=(0,1,1), mle_regression=True, suppress_warnings=True)\n",
    "model_111 = ARIMA(order=(1,1,1), mle_regression=True, suppress_warnings=True)\n",
    "model_211 = ARIMA(order=(2,1,1), mle_regression=True, suppress_warnings=True)\n",
    "model_210 = ARIMA(order=(2,1,0), mle_regression=True, suppress_warnings=True)\n",
    "\n",
    "train_X = []; train_Y = []\n",
    "dev_X = []; dev_Y = []\n",
    "test1_X = []; test1_Y = []\n",
    "test2_X = []; test2_Y = []\n",
    "\n",
    "flag = 0\n",
    "\n",
    "#Iterating thorugh different SARIMAX models for all the data sets\n",
    "for i in range(55875):\n",
    "    print(i)\n",
    "    tmp = []\n",
    "    c=0\n",
    "    for s in datasets :\n",
    "        c+=1\n",
    "        try:\n",
    "            model1 = model_110.fit(s[i])\n",
    "            model = model1\n",
    "            \n",
    "            try:\n",
    "                model2 = model_011.fit(s[i])\n",
    "                \n",
    "                #use of Akaike Information Criterion for determining better fitting model\n",
    "                if model.aic() <= model2.aic() :\n",
    "                    pass\n",
    "                else :\n",
    "                    model = model2\n",
    "                    \n",
    "                try :\n",
    "                    model3 = model_111.fit(s[i])\n",
    "                    if model.aic() <= model3.aic() :\n",
    "                        pass\n",
    "                    else :\n",
    "                        model = model3\n",
    "                except :\n",
    "                    try:\n",
    "                        model4 = model_211.fit(s[i])\n",
    "                        \n",
    "                        if model.aic() <= model4.aic() :\n",
    "                            pass\n",
    "                        else:\n",
    "                            model = model4\n",
    "                    except:\n",
    "                        try:\n",
    "                            model5 = model_210.fit(s[i])\n",
    "                            \n",
    "                            if model.aic() <= model5.aic():\n",
    "                                pass\n",
    "                            else :\n",
    "                                model = model5\n",
    "                        except :\n",
    "                            pass\n",
    "                    \n",
    "            except:\n",
    "                try:\n",
    "                    model3 = model_111.fit(s[i])\n",
    "\n",
    "                    if model.aic() <= model3.aic() :\n",
    "                        pass\n",
    "                    else :\n",
    "                        model = model3\n",
    "                except :\n",
    "                    try:\n",
    "                        model4 = model_211.fit(s[i])\n",
    "                        \n",
    "                        if model.aic() <= model4.aic() :\n",
    "                            pass\n",
    "                        else:\n",
    "                            model = model4\n",
    "                    except:\n",
    "                        try:\n",
    "                            model5 = model_210.fit(s[i])\n",
    "                            \n",
    "                            if model.aic() <= model5.aic():\n",
    "                                pass\n",
    "                            else :\n",
    "                                model = model5\n",
    "                        except :\n",
    "                            pass\n",
    "                \n",
    "        except:\n",
    "            try:\n",
    "                model2 = model_011.fit(s[i])\n",
    "                model = model2\n",
    "            \n",
    "                try :\n",
    "                    model3 = model_111.fit(s[i])\n",
    "                    \n",
    "                    if model.aic() <= model3.aic():\n",
    "                        pass\n",
    "                    else:\n",
    "                        model = model3\n",
    "                except :\n",
    "                    try:\n",
    "                        model4 = model_211.fit(s[i])\n",
    "                        \n",
    "                        if model.aic() <= model4.aic() :\n",
    "                            pass\n",
    "                        else:\n",
    "                            model = model4\n",
    "                    except:\n",
    "                        try:\n",
    "                            model5 = model_210.fit(s[i])\n",
    "                            \n",
    "                            if model.aic() <= model5.aic():\n",
    "                                pass\n",
    "                            else :\n",
    "                                model = model5\n",
    "                        except :\n",
    "                            pass\n",
    "            \n",
    "            except :\n",
    "                try:\n",
    "                    model3 = model_111.fit(s[i])\n",
    "                    model = model3\n",
    "                except :\n",
    "                    try:\n",
    "                        model4 = model_211.fit(s[i])\n",
    "                        \n",
    "                        if model.aic() <= model4.aic() :\n",
    "                            pass\n",
    "                        else:\n",
    "                            model = model4\n",
    "                    except:\n",
    "                        try:\n",
    "                            model5 = model_210.fit(s[i])\n",
    "                            \n",
    "                            if model.aic() <= model5.aic():\n",
    "                                pass\n",
    "                            else :\n",
    "                                model = model5\n",
    "                        except :\n",
    "                            flag = 1\n",
    "                            print(str(c) + \" FATAL ERROR\")\n",
    "                            break\n",
    "        \n",
    "        predictions = list(model.predict_in_sample())\n",
    "        #pad the first time step of predictions with the average of the prediction values\n",
    "        #so as to match the length of the s[i] data\n",
    "        predictions = [np.mean(predictions)] + predictions\n",
    "        \n",
    "        residual = model.resid()\n",
    "        tmp.append(np.array(residual))\n",
    "        \n",
    "                    \n",
    "    if flag == 1:\n",
    "        break\n",
    "    train_X.append(tmp[0][:20])\n",
    "    train_Y.append(tmp[0][20])\n",
    "    dev_X.append(tmp[1][:20])\n",
    "    dev_Y.append(tmp[1][20])\n",
    "    test1_X.append(tmp[2][:20])\n",
    "    test1_Y.append(tmp[2][20])\n",
    "    test2_X.append(tmp[3][:20])\n",
    "    test2_Y.append(tmp[3][20])\n",
    "    \n",
    "#Save residual values which will be used as input to LSTM model\n",
    "pd.DataFrame(train_X).to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Post_ARIMA/train_X.csv')\n",
    "pd.DataFrame(dev_X).to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Post_ARIMA/dev_X.csv')\n",
    "pd.DataFrame(test1_X).to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Post_ARIMA/test1_X.csv')\n",
    "pd.DataFrame(test2_X).to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Post_ARIMA/test2_X.csv')\n",
    "pd.DataFrame(train_Y).to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Post_ARIMA/train_Y.csv')\n",
    "pd.DataFrame(dev_Y).to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Post_ARIMA/dev_Y.csv')\n",
    "pd.DataFrame(test1_Y).to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Post_ARIMA/test1_Y.csv')\n",
    "pd.DataFrame(test2_Y).to_csv('/Users/gauravthapliyal/Desktop/Project Data/train_dev_test/Post_ARIMA//test2_Y.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
