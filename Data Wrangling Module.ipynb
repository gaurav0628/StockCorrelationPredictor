{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module builds upon data extracted in data scraping module. Here first we select stocks for which data exists \n",
    "for previous 10 years. From those stocks 150 stocks are randomly selected to create portfolio. After portfolio \n",
    "creation, I check for any missing data and impute such entries. Finally calculate correlation coefficient matrix\n",
    "which can be passed on to ARIMA module for forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 1 contains imports which will be required to run this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 1 - Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 2 - Select stocks for which data is present since 2010\n",
    "\n",
    "path = '/Users/gauravthapliyal/Desktop/Project Data/ticker_stock_data/'\n",
    "stock_from2010 = []\n",
    "for file in os.listdir(path):\n",
    "    file_path = path + '/' + file\n",
    "    date = pd.read_csv(file_path)['date']\n",
    "    df=pd.DataFrame(data=date)\n",
    "    if len(date)>0 and df['date'].iat[-1] <= '2010-01-01' :\n",
    "        stock_from2010.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 3 : Create a dictionary of Adjusted Close Price for all the stocks extracted in the previous cell.\n",
    "stock_price_dict = {}\n",
    "\n",
    "#run a loop for all the tickers for which data after 2010 is present.\n",
    "#extract adjusted close price of stock and append in the dictionary.\n",
    "for file in stock_from2010 :\n",
    "    path = \"/Users/gauravthapliyal/Desktop/Project Data/ticker_stock_data/\" + file\n",
    "    df_stock = pd.read_csv(path)\n",
    "    df_stock = df_stock[df_stock.date >= '2010-01-01']\n",
    "    pd.to_datetime(df_stock['date'], format='%Y-%m-%d')\n",
    "    df_stock = df_stock.set_index(pd.DatetimeIndex(df_stock['date']))\n",
    "    stock_price_dict[file.split(\".\")[0]] = df_stock['5. adjusted close']\n",
    "\n",
    "#extract adjusted close value for combines ticker of SP500 firms and append that single column to dictionary\n",
    "#SP500_index.csv contains stocks data for the combined representation ticker (GSPC) of SP500 firms\n",
    "market_path = \"/Users/gauravthapliyal/Desktop/Project Data/SP500_index.csv\"\n",
    "df = pd.read_csv(market_path)\n",
    "df = df[df.Date >= '2010-01-01']\n",
    "pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "df = df.set_index(pd.DatetimeIndex(df['Date']))\n",
    "stock_price_dict['SP500'] = df['Adj Close']\n",
    "\n",
    "#save the dictionary in a csv\n",
    "stock_price_df = pd.DataFrame(stock_price_dict)\n",
    "data_dir = \"/Users/gauravthapliyal/Desktop/Project Data/test.csv\"\n",
    "stock_price_df.to_csv(data_dir)\n",
    "print(stock_price_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 4 - Detecting anomalies in data\n",
    "\n",
    "missing_ratio = []\n",
    "missing_col = []\n",
    "\n",
    "print(\"Values are not available for the following ticker\")\n",
    "\n",
    "#Checks if adjusted close price for any ticker is blank\n",
    "#Counts the number of missing values for given index of a ticker\n",
    "\n",
    "for column in stock_price_df.columns :\n",
    "    miss_index = np.where(stock_price_df[column].isnull())[0]\n",
    "    missing_col.append(column)\n",
    "    missing_ratio.append(len(miss_index)/stock_price_df.shape[0] * 100)\n",
    "    if miss_index > 0:\n",
    "        print(column,miss_index)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a single ticker DISH is missing a single value. Since number of missing values is less than 5 for all the tickers, hence we will impute the value. For imputing we will use next day value and use it for the missing day. If more than 5 values missing, then uncomment deletion code and delete that ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 5 - Data Imputation\n",
    "\n",
    "#Function definition to impute data.\n",
    "def impute_data(column_name):\n",
    "    index = stock_price_df.index.values[0]\n",
    "    price_na_index = np.where(stock_price_df[column_name].isnull())[0]\n",
    "    for i in price_na_index :\n",
    "        stock_price_df[column_name][i] = stock_price_df[column_name][i-1]\n",
    "        \n",
    "for item in stock_price_df.columns :\n",
    "    impute_data(item)\n",
    "\n",
    "#corrupt_tickers = [] -- fill this array with tickers \n",
    "#for i in corrupt_tickers:\n",
    "#    stock_price_df.remove(i)\n",
    "    \n",
    "print(\"Data is now clean. Proceeding to load data.\")\n",
    "\n",
    "stock_price_df.to_csv(\"/Users/gauravthapliyal/Desktop/Project Data/stock_pricefrom2010.csv\",index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 6 - Portfolio Creation\n",
    "\n",
    "#Load dictionary of adjusted close prices\n",
    "df = pd.read_csv(\"/Users/gauravthapliyal/Desktop/Project Data/stock_pricefrom2010.csv\")\n",
    "all_firms = list(df.columns.values[1:])\n",
    "portfolio = list(stock_price_df.columns)\n",
    "portfolio.pop()\n",
    "\n",
    "#Create a portfolio of randomly selected 150 S&P500 firms\n",
    "random.shuffle(all_firms)\n",
    "portfolio = universe[:150].copy()\n",
    "print(portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 7 - Function for calculation rolling correlation matrix\n",
    "\n",
    "def get_rolling_corr(item1,item2) :\n",
    "    \n",
    "    stock_price_df = pd.read_csv(\"/Users/gauravthapliyal/Desktop/Project Data/stock_pricefrom2010.csv\")\n",
    "    pd.to_datetime(stock_price_df['Date'], format='%Y-%m-%d')\n",
    "    stock_price_df = stock_price_df.set_index(pd.DatetimeIndex(stock_price_df['Date']))\n",
    "    \n",
    "    df_pair = pd.concat([stock_price_df[item1], stock_price_df[item2]], axis=1)\n",
    "    df_pair.columns = [item1,item2]\n",
    "    df_corr = df_pair[item1].rolling(window=100).corr(df_pair[item2])\n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = ['FRT', 'AMD', 'MOS', 'DVN', 'RE', 'INTU', 'STE', 'JKHY', 'EXR', 'ZBRA', 'CMI', 'AMP', 'VNO', 'EMN', 'HSY', 'DAL', 'EQIX', 'ADP', 'PPL', 'LKQ', 'MS', 'EW', 'PPG', 'TSCO', 'MYL', 'XRX', 'VLO', 'JBHT', 'HPQ', 'FTI', 'FAST', 'AVGO', 'CVX', 'DGX', 'MGM', 'NVR', 'GE', 'LYV', 'REGN', 'AAL', 'PWR', 'RHI', 'EMR', 'ALL', 'HUM', 'CPRT', 'NLOK', 'CF', 'NVDA', 'HD', 'MRO', 'CMCSA', 'MET', 'MAR', 'DISCA', 'SLG', 'URI', 'RL', 'FLS', 'BAC', 'NEE', 'CAT', 'DG', 'PCAR', 'DLR', 'NI', 'GILD', 'O', 'TEL', 'ESS', 'DLTR', 'GS', 'ALK', 'KSS', 'NOV', 'UNP', 'ES', 'HAL', 'GLW', 'TAP', 'SPGI', 'CVS', 'IPG', 'UNH', 'WYNN', 'PXD', 'IEX', 'DIS', 'ROP', 'MKTX', 'NEM', 'LDOS', 'HOG', 'CNC', 'TJX', 'AMAT', 'MDT', 'PVH', 'AKAM', 'INCY', 'TROW', 'HWM', 'ULTA', 'KR', 'AAPL', 'PNC', 'BDX', 'ADM', 'AJG', 'BXP', 'SRE', 'VZ', 'NTRS', 'HON', 'BEN', 'TRV', 'HAS', 'CCI', 'FIS', 'FFIV', 'KEY', 'CTSH', 'IDXX', 'DRE', 'DISH', 'MSI', 'ADS', 'CDNS', 'ADI', 'AOS', 'KLAC', 'HRB', 'KMX', 'ISRG', 'EL', 'GOOGL', 'ARE', 'PEP', 'CTL', 'EXC', 'TGT', 'HIG', 'ROL', 'COO', 'CI', 'SBAC', 'BKNG', 'GWW', 'WY', 'RJF']\n",
    "print(len(portfolio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 8 Calculate correlation cpefficient matrix and saving it in csv form\n",
    "\n",
    "#create a list of indices\n",
    "index_list = []\n",
    "for _ in range(100):\n",
    "    indices = []\n",
    "    for k in range(_, 2420,100):\n",
    "        indices.append(k)\n",
    "    index_list.append(indices)\n",
    "\n",
    "#calculate rolling correlation\n",
    "data_matrix = []\n",
    "count = 0\n",
    "for i in range(150):\n",
    "    for j in range(149-i):\n",
    "        a = portfolio[i]\n",
    "        b = portfolio[149-j]\n",
    "        file_name = a + '_' + b\n",
    "            \n",
    "        corr_series = get_rolling_corr(a, b)[99:]\n",
    "        for _ in range(100):\n",
    "            corr_strided = list(corr_series[index_list[_]][:24]).copy()\n",
    "            data_matrix.append(corr_strided)\n",
    "            count+=1\n",
    "            if count % 1000 == 0 :\n",
    "                print(str(count)+' items extracted and transformed')\n",
    "\n",
    "#calculate coefficient correlation matrix and save it in csv form\n",
    "data_matrix = np.transpose(data_matrix)\n",
    "data_dictionary = {}\n",
    "for i in range(len(data_matrix)):\n",
    "    data_dictionary[str(i)] = data_matrix[i]\n",
    "data_df = pd.DataFrame(data_dictionary)\n",
    "data_df.to_csv('/Users/gauravthapliyal/Desktop/Project Data/stock_correlation_prediction/Correlation_Matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
